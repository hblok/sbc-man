10.1 UNIT TEST STRATEGY (FULL)
===============================

UNIT TESTING APPROACH (unittest)
================================

Test Framework: unittest (Python standard library)

Directory Structure:
tests/
├── unit/
│   ├── test_models.py
│   ├── test_hardware_detection.py
│   ├── test_config_loader.py
│   ├── test_input_handler.py
│   ├── test_file_ops.py
│   └── test_game_library.py
├── integration/
│   ├── test_state_transitions.py
│   ├── test_download_flow.py
│   └── test_game_launch.py
├── fixtures/
│   ├── test_configs/
│   └── test_games/
└── conftest.py    # (Optional in unittest; helper modules can be regular .py files)

Key Test Categories:

1. Model Tests (test_models.py)
   ├─ Game serialization/deserialization
   ├─ Game.to_dict() produces valid structure
   ├─ Game.from_dict() reconstructs correctly
   ├─ Round-trip: game == Game.from_dict(game.to_dict())
   └─ Handles missing optional fields

   Example Tests (unittest):
   import unittest
   from models.game import Game

   class TestModels(unittest.TestCase):
       def test_game_to_dict(self):
           game = Game(game_id="test", name="Test Game", installed=False)
           data = game.to_dict()
           self.assertEqual(data['id'], "test")
           self.assertEqual(data['name'], "Test Game")
           self.assertIn('installed', data)

       def test_game_from_dict(self):
           data = {"id": "test", "name": "Test", "installed": True}
           game = Game.from_dict(data)
           self.assertEqual(game.id, "test")
           self.assertIsInstance(game, Game)

       def test_game_round_trip(self):
           original = Game(game_id="test", name="Test", installed=True)
           data = original.to_dict()
           restored = Game.from_dict(data)
           self.assertEqual(original.id, restored.id)
           self.assertEqual(original.name, restored.name)

2. Hardware Detection Tests
   ├─ Mock file system for device detection
   ├─ Test each device type recognition
   ├─ Test OS type detection
   ├─ Test fallback to defaults
   └─ Test probe failures return safe values

   Example Tests (unittest + mock):
   import unittest
   from unittest import mock
   from hardware.detector import HardwareDetector
   from hardware.prober import HardwareProber

   class TestHardware(unittest.TestCase):
       @mock.patch('builtins.open', new_callable=mock.mock_open, read_data="Anbernic RG353")
       @mock.patch('pathlib.Path.exists', return_value=True)
       def test_detect_anbernic_device(self, _exists, _open):
           device_type = HardwareDetector._detect_device()
           self.assertEqual(device_type, "anbernic")

       @mock.patch('pathlib.Path.exists', return_value=False)
       def test_unknown_device_fallback(self, _exists):
           device_type = HardwareDetector._detect_device()
           self.assertEqual(device_type, "desktop")

       @mock.patch('pygame.display.Info', side_effect=Exception)
       def test_display_probe_failure(self, _info):
           # Provide a safe fallback in your implementation if needed
           result = HardwareProber.probe_display()
           # Assuming your prober returns dict with current_resolution
           self.assertIn('current_resolution', result)

3. Configuration Loading Tests
   ├─ Test layer merging logic
   ├─ Test each configuration layer loads
   ├─ Test deep merge preserves nested structures
   ├─ Test malformed JSON handling
   ├─ Test missing file handling
   └─ Test validation catches invalid values

   Example Tests (unittest):
   import unittest
   from hardware.config_loader import ConfigLoader

   class TestConfigLoader(unittest.TestCase):
       def test_config_deep_merge(self):
           base = {"display": {"resolution": [640, 480], "fullscreen": False}}
           override = {"display": {"fullscreen": True}}
           result = ConfigLoader._merge(base, override)
           self.assertEqual(result['display']['resolution'], [640, 480])
           self.assertTrue(result['display']['fullscreen'])

       def test_missing_config_file(self):
           loader = ConfigLoader("nonexistent", "standard_linux", {})
           config = loader.load_config()
           self.assertIn('device', config)
           self.assertIn('display', config)

       def test_malformed_json_handling(self):
           # Implement _load_json to safely return None on malformed JSON
           result = ConfigLoader._load_json("nonexistent_or_bad.json")
           # Expect None or a handled response
           self.assertIsNone(result)

4. Input Mapping Tests
   ├─ Test action resolution
   ├─ Test layer hierarchy (higher layers win)
   ├─ Test button name mapping
   ├─ Test keyboard event matching
   ├─ Test joystick event matching
   ├─ Test d-pad event matching
   └─ Test save/load custom mappings

   Example Tests (unittest):
   import unittest
   import pygame
   from services.input_handler import InputHandler

   class TestInputHandler(unittest.TestCase):
       def setUp(self):
           self.hw_config = {
               "device": {"detected_type": "desktop"},
               "paths": {"data": "/tmp"},
               "display": {"resolution": [800, 600], "fullscreen": False}
           }
           self.handler = InputHandler(self.hw_config)

       def test_keyboard_action_pressed(self):
           self.handler.mappings = {"confirm": ["K_RETURN"]}
           event = pygame.event.Event(pygame.KEYDOWN, key=pygame.K_RETURN)
           self.assertTrue(self.handler.is_action_pressed("confirm", [event]))

       def test_button_name_mapping(self):
           names = self.handler._get_button_names(0)
           self.assertIn("BUTTON_0", names)
           self.assertIn("BUTTON_A", names)
           self.assertIn("BUTTON_SOUTH", names)

       def test_layer_hierarchy_with_subTest(self):
           # Example of replacing parametrize with subTest
           scenarios = [
               ({"confirm": ["BUTTON_1"]}, "BUTTON_1", True),
               ({"confirm": ["BUTTON_2"]}, "BUTTON_1", False),
           ]
           for mapping, check, expected in scenarios:
               with self.subTest(mapping=mapping, check=check, expected=expected):
                   self.handler.mappings = mapping
                   # Simulate JOYBUTTONDOWN with index parsed by _get_button_names
                   event = pygame.event.Event(pygame.JOYBUTTONDOWN, button=1)
                   result = self.handler.is_action_pressed("confirm", [event])
                   self.assertEqual(result, expected)

5. File Operations Tests
   ├─ Test directory creation
   ├─ Test archive extraction (zip, tar.gz)
   ├─ Test free space checking
   ├─ Test permission handling
   └─ Test cleanup on errors

   Example Tests (unittest):
   import unittest
   from tempfile import TemporaryDirectory
   from pathlib import Path
   import zipfile
   from services.file_ops import FileOps

   class TestFileOps(unittest.TestCase):
       def test_ensure_dir_creates_directory(self):
           with TemporaryDirectory() as td:
               test_dir = Path(td) / "new_dir"
               result = FileOps.ensure_dir(test_dir)
               self.assertTrue(test_dir.exists())
               self.assertEqual(result, test_dir)

       def test_extract_zip_archive(self):
           with TemporaryDirectory() as td:
               zip_path = Path(td) / "test.zip"
               with zipfile.ZipFile(zip_path, 'w') as zf:
                   zf.writestr("test.txt", "content")

               extract_dir = Path(td) / "extracted"
               FileOps.extract_archive(zip_path, extract_dir)
               self.assertTrue((extract_dir / "test.txt").exists())

       def test_get_free_space(self):
           with TemporaryDirectory() as td:
               space = FileOps.get_free_space(td)
               self.assertIsInstance(space, int)
               self.assertGreater(space, 0)

6. Game Library Tests
   ├─ Test add/remove/get games
   ├─ Test save/load persistence
   ├─ Test search functionality
   ├─ Test filter by installed status
   └─ Test empty library handling

   Example Tests (unittest):
   import unittest
   from tempfile import TemporaryDirectory
   from pathlib import Path
   from models.game import Game
   from models.game_library import GameLibrary

   class TestGameLibrary(unittest.TestCase):
       def setUp(self):
           self.hw_config = {"paths": {"data": ""}}
           self.library = GameLibrary(self.hw_config)

       def test_add_and_get_game(self):
           game = Game(game_id="test", name="Test Game")
           self.library.add_game(game)
           self.assertEqual(self.library.get_game("test"), game)

       def test_remove_game(self):
           game = Game(game_id="test", name="Test")
           self.library.add_game(game)
           self.library.remove_game("test")
           self.assertIsNone(self.library.get_game("test"))

       def test_library_persistence(self):
           with TemporaryDirectory() as td:
               data_path = Path(td) / "games.json"
               self.library.library_path = data_path
               game = Game(game_id="test", name="Test")
               self.library.add_game(game)
               self.library.save()

               library2 = GameLibrary(self.hw_config)
               library2.library_path = data_path
               library2.load()
               self.assertEqual(library2.get_game("test").name, "Test")

7. Network Service Tests
   ├─ Mock HTTP requests
   ├─ Test download with progress
   ├─ Test JSON fetching
   ├─ Test connectivity checks
   └─ Test error handling

   Example Tests (unittest + mock):
   import unittest
   from unittest import mock
   from pathlib import Path
   from services.network import NetworkService

   class TestNetworkService(unittest.TestCase):
       @mock.patch('requests.get')
       def test_download_file(self, mock_get):
           mock_response = mock.Mock()
           mock_response.headers = {'Content-Length': '100'}
           mock_response.iter_content = lambda chunk_size: [b'x' * 100]
           mock_response.__enter__ = lambda s: s
           mock_response.__exit__ = lambda s, exc_type, exc, tb: None
           mock_get.return_value = mock_response

           with TemporaryDirectory() as td:
               dest = Path(td) / "download.bin"
               result = NetworkService.download_file("http://test.com/file", dest)
               self.assertTrue(result)
               self.assertTrue(dest.exists())

       @mock.patch('requests.get')
       def test_fetch_json(self, mock_get):
           resp = mock.Mock()
           resp.json.return_value = {"key": "value"}
           resp.status_code = 200
           mock_get.return_value = resp
           result = NetworkService.fetch_json("http://test.com/api")
           self.assertEqual(result, {"key": "value"})

8. State Tests
   ├─ Test state lifecycle (on_enter/on_exit)
   ├─ Test state-specific logic
   ├─ Test view interactions
   └─ Test error handling in states

   Example Tests (unittest):
   import unittest
   from unittest import mock
   from states.menu_state import MenuState

   class TestStates(unittest.TestCase):
       def test_menu_state_navigation(self):
           state_manager = mock.Mock()
           state = MenuState(state_manager)
           state.on_enter(None)
           initial = state.view.selected_index

           # Simulate 'down' action via input handler mock if needed
           state.view.set_selected_index(initial + 1)
           self.assertEqual(state.view.selected_index, initial + 1)

9. Download Manager Tests
   ├─ Test observer registration
   ├─ Test progress notifications
   ├─ Test concurrent downloads
   └─ Test error notifications

   Example Tests (unittest):
   import unittest
   from unittest import mock
   from models.download_manager import DownloadManager

   class TestDownloadManager(unittest.TestCase):
       def test_add_observer(self):
           manager = DownloadManager(hw_config={})
           observer = mock.Mock()
           manager.add_observer(observer)
           self.assertIn(observer, manager.observers)

       def test_notify_progress(self):
           manager = DownloadManager(hw_config={})
           observer = mock.Mock()
           manager.add_observer(observer)
           manager.notify_progress("dl1", {"percent": 50})
           observer.on_progress_update.assert_called_with("dl1", {"percent": 50})

       def test_concurrent_downloads(self):
           manager = DownloadManager(hw_config={})
           dl1 = manager.start_download({"id": "g1", "download_url": "http://x"}, Path("/tmp"))
           dl2 = manager.start_download({"id": "g2", "download_url": "http://y"}, Path("/tmp"))
           self.assertNotEqual(dl1, dl2)
           self.assertIn(dl1, manager.downloads)
           self.assertIn(dl2, manager.downloads)

Test Utilities:
-------------------------------------------
- Use setUp/setUpClass/tearDown/tearDownClass in unittest.TestCase to prepare common state.
- Use helper factory functions or base TestCase classes to share config setup across tests.

Example Common Helpers:
from unittest import TestCase

def make_test_hw_config(tmp_data_dir="/tmp"):
    return {
        "device": {"name": "Test Device", "type": "desktop"},
        "display": {"resolution": [800, 600], "fullscreen": False},
        "paths": {
            "games": f"{tmp_data_dir}/games",
            "data": tmp_data_dir,
            "config": f"{tmp_data_dir}/config",
            "cache": f"{tmp_data_dir}/cache"
        },
        "performance": {"target_fps": 60, "vsync": True},
        "launcher": {"python_command": "python3"}
    }

class BaseAppTestCase(TestCase):
    def setUp(self):
        # Create application with headless pygame and mocks as needed
        self.hw_config = make_test_hw_config()
        self.app = create_test_application(hw_config=self.hw_config)

Parametrization Replacement:
---------------------------
Example:
for value in [1, 2, 3]:
    with self.subTest(value=value):
        self.assertGreaterEqual(value, 1)

Coverage Goals:
├─ Models: 100% (simple data classes)
├─ Core Logic: 90%+ (hardware, config, input)
├─ Services: 85%+ (file ops, network)
├─ States: 75%+ (complex UI interactions)
└─ Overall Target: 85%+

Running Tests:
# All tests via discovery
python3 -m unittest discover -s tests -p "test_*.py"

# Unit tests only
python3 -m unittest discover -s tests/unit -p "test_*.py"

# With coverage
coverage run -m unittest discover -s tests
coverage report -m
# Optional HTML report
coverage html

# Specific test module (verbose)
python3 -m unittest -v tests.unit.test_models

# Specific test case or method
python3 -m unittest -v tests.unit.test_models.TestModels.test_game_to_dict
